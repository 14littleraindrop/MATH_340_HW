\documentclass{article}

\usepackage[english]{babel}
\usepackage{fancyhdr}
\pagestyle{fancy}
\fancyhf{}
\lhead{WINTER 2021 --- MATH 340 HW1}
\rhead{Helen (Yeu) Chen}
\setlength{\parindent}{0cm}
\usepackage{makecell}
\usepackage{amsfonts}
\usepackage{longtable}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}

\fancyfoot[C]{\thepage}

\begin{document}


$ \bullet$ \textbf{Problem 1}
\medskip

\begin{itshape}
Show that the set $\mathcal{V}$ of all real valued $n \times m$ matrices with the usual matrix addition and scalar multiplication is a vector space over $\mathbb{R}$ for any $n \ge 1$, $m \ge1$.
\end{itshape}
\medskip

\begin{proof}
$ $\newline
Let $A$, $B$ and $C$ be $n \times m$ matrices with $n,m \ge 1$, that is 
$$A = \begin{pmatrix} a_{11} & a_{12} & \ldots & a_{1m} \\ a_{21} & a_{22} & \ldots  & a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \ldots & a_{nm} \end{pmatrix}, B = \begin{pmatrix} b_{11} & b_{12} & \ldots & b_{1m} \\ b_{21} & b_{22} & \ldots  & b_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ b_{n1} & b_{n2} & \ldots & b_{nm} \end{pmatrix}, C= \begin{pmatrix} c_{11} & c_{12} & \ldots & c_{1m} \\ c_{21} & c_{22} & \ldots  & c_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ c_{n1} & c_{n2} & \ldots & c_{nm} \end{pmatrix}$$

Let $a, b \in \mathbb{R}$.
\smallskip

\textbf{1. $+$ is commutative:}
\begin{align*}
A + B &= \begin{pmatrix} a_{11} & a_{12} & \ldots & a_{1m} \\ a_{21} & a_{22} & \ldots  & a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \ldots & a_{nm} \end{pmatrix} +  \begin{pmatrix} b_{11} & b_{12} & \ldots & b_{1m} \\ b_{21} & b_{22} & \ldots  & b_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ b_{n1} & b_{n2} & \ldots & b_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11} + b_{11} & a_{12} + b_{12} & \ldots & a_{1m} + b_{1m} \\ a_{21} + b_{21} & a_{22} + b_{22} & \ldots  & a_{2m} + b_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} + b_{n1} & a_{n2} +  b_{n2} & \ldots & a_{nm} + b_{nm} \end{pmatrix} \\
&= \begin{pmatrix} b_{11} + a_{11} & b_{12} + a_{12} & \ldots & b_{1m} + a_{1m} \\ b_{21} + a_{21} & b_{22} + a_{22} & \ldots  & b_{2m} + a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ b_{n1} + a_{n1} & b_{n2} + a_{n2} & \ldots & b_{nm} + a_{nm} \end{pmatrix} \text{(by commutative of addition of reals)} \\
&=  \begin{pmatrix} b_{11} & b_{12} & \ldots & b_{1m} \\ b_{21} & b_{22} & \ldots  & b_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ b_{n1} & b_{n2} & \ldots & b_{nm} \end{pmatrix} + \begin{pmatrix} a_{11} & a_{12} & \ldots & a_{1m} \\ a_{21} & a_{22} & \ldots  & a_{2m} \\ \vdots & \vdots & \ddots & \vdots \\ a_{n1} & a_{n2} & \ldots & a_{nm} \end{pmatrix} \\
&= B+ A
\end{align*}
Hence addition is commutative in the vector space.
\smallskip

\textbf{2. $+$ is associative:}
\begin{align*}
(A + B) + C &= (\begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} +  \begin{pmatrix} b_{11} &  \ldots & b_{1m} \\  \vdots & \ddots & \vdots \\ b_{n1} &  \ldots & b_{nm} \end{pmatrix}) + \begin{pmatrix} c_{11} &  \ldots & c_{1m} \\ \vdots & \ddots & \vdots \\ c_{n1} & \ldots & c_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11} + b_{11} & \ldots & a_{1m} + b_{1m} \\ \vdots & \ddots & \vdots \\ a_{n1} + b_{n1} & \ldots & a_{nm} + b_{nm} \end{pmatrix} + \begin{pmatrix} c_{11} &  \ldots & c_{1m}  \\ \vdots & \ddots & \vdots \\ c_{n1} & \ldots & c_{nm} \end{pmatrix} \\
&= \begin{pmatrix} (a_{11} + b_{11}) + c_{11} & \ldots & (a_{1m} + b_{1m}) + c_{1m} \\  \vdots & \ddots & \vdots \\ (a_{n1} + b_{n1}) + c_{n1} & \ldots & (a_{nm} + b_{nm}) + c_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11} + (b_{11} + c_{11}) & \ldots & a_{1m} + (b_{1m} + c_{1m}) \\  \vdots & \ddots & \vdots \\ a_{n1} + (b_{n1} + c_{n1}) & \ldots & a_{nm} + (b_{nm} + c_{nm}) \end{pmatrix} \text{(by associativity of addition of reals)} \\
&= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} + \begin{pmatrix} b_{11} + c_{11} &  \ldots & b_{1m} + c_{1m} \\  \vdots & \ddots & \vdots \\ b_{n1} +c_{n1} &  \ldots & b_{nm} + c_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} +  (\begin{pmatrix} b_{11} &  \ldots & b_{1m} \\  \vdots & \ddots & \vdots \\ b_{n1} &  \ldots & b_{nm} \end{pmatrix} + \begin{pmatrix} c_{11} &  \ldots & c_{1m} \\ \vdots & \ddots & \vdots \\ c_{n1} & \ldots & c_{nm} \end{pmatrix}) \\
&= A + (B+ C)
\end{align*}
Hence addition is associative in the vector space.
\smallskip

\textbf{3. identity for $+$:}

Let $\vec{0}$ be a $n \times m$ matrix with all zero entries. Then
\begin{align*}
A + \vec{0} &= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} + \begin{pmatrix} 0 & \ldots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \ldots & 0 \end{pmatrix} \\
&=  \begin{pmatrix} a_{11} + 0 & \ldots & a_{1m} +0  \\ \vdots &  \ddots & \vdots \\ a_{n1} +0 &  \ldots & a_{nm} +0 \end{pmatrix} \\
&= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} \text{(given that $0$ is the identity for addition for reals)} \\
&= A
\end{align*}
Hence the zero matrix (which is also element of $\mathcal{V}$) is the identity for addition for this vector field.
\smallskip

\textbf{4. additive inverse:}

Take $$-A = \begin{pmatrix} -a_{11} & \ldots & -a_{1m} \\ \vdots &  \ddots & \vdots \\ -a_{n1} &  \ldots & -a_{nm} \end{pmatrix} $$
Then 
\begin{align*}
A + (-A) &= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} + \begin{pmatrix} -a_{11} & \ldots & -a_{1m} \\ \vdots &  \ddots & \vdots \\ -a_{n1} &  \ldots & -a_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11}+(-a_{11}) & \ldots & a_{1m}+ (-a_{1m}) \\ \vdots &  \ddots & \vdots \\ a_{n1}+(-a_{n1}) &  \ldots & a_{nm}+(-a_{nm}) \end{pmatrix} \\
&= \begin{pmatrix} 0 & \ldots & 0 \\ \vdots & \ddots & \vdots \\ 0 & \ldots & 0 \end{pmatrix} \\
&= \vec{0}
\end{align*}
Hence for all $A \in \mathcal{V}$, $-A$ defined as above is its additive inverse.
\smallskip

\textbf{5. multiplicative identity:}

Take the multiplicative identity to be $1 \in \mathbb{R}$. Then
\begin{align*}
1 \cdot  A &= 1 \cdot \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} \\
&= \begin{pmatrix} 1 \cdot a_{11} & \ldots & 1 \cdot a_{1m} \\ \vdots &  \ddots & \vdots \\ 1 \cdot a_{n1} &  \ldots & 1 \cdot a_{nm} \end{pmatrix} \\
&= \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix}\\
&= A
\end{align*}
Hence $1$ is the multiplicative inverse.
\smallskip

\textbf{6. $(a \cdot b) A = a \cdot (b \cdot A)$:}
\begin{align*}
(a \cdot b) A &= ab \cdot \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} \\
&= \begin{pmatrix} (ab) \cdot a_{11} & \ldots & (ab) \cdot a_{1m} \\ \vdots &  \ddots & \vdots \\ (ab) \cdot a_{n1} &  \ldots & (ab) \cdot a_{nm} \end{pmatrix} \\ 
&=  \begin{pmatrix} a(b \cdot a_{11}) & \ldots & a(b \cdot a_{1m}) \\ \vdots &  \ddots & \vdots \\ a(b \cdot a_{n1}) &  \ldots & a(b \cdot a_{nm}) \end{pmatrix} \text{(by associativity of multiplication of reals)}\\
&=  a \cdot \begin{pmatrix} b \cdot a_{11} & \ldots & b \cdot a_{1m} \\ \vdots &  \ddots & \vdots \\ b \cdot a_{n1} &  \ldots & b \cdot a_{nm} \end{pmatrix} \\
&= a \cdot (b \cdot \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix}) \\
&= a \cdot (b \cdot A)
\end{align*}
\smallskip

\textbf{7. $a(A+B)=aA+aB$:}
\begin{align*}
a(A+B) &= a(\begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} + \begin{pmatrix} b_{11} &  \ldots & b_{1m} \\  \vdots & \ddots & \vdots \\ b_{n1} &  \ldots & b_{nm} \end{pmatrix}) \\
&= a\begin{pmatrix} a_{11} + b_{11} & \ldots & a_{1m} + b_{1m} \\ \vdots & \ddots & \vdots \\ a_{n1} + b_{n1} & \ldots & a_{nm} + b_{nm} \end{pmatrix}\\
&= \begin{pmatrix} a(a_{11} + b_{11}) & \ldots & a(a_{1m} + b_{1m}) \\ \vdots & \ddots & \vdots \\ a(a_{n1} + b_{n1}) & \ldots & a(a_{nm} + b_{nm}) \end{pmatrix}\\
&= \begin{pmatrix} aa_{11} + ab_{11} & \ldots & aa_{1m} + ab_{1m} \\ \vdots & \ddots & \vdots \\ aa_{n1} + ab_{n1} & \ldots & aa_{nm} + ab_{nm} \end{pmatrix} \text{(since multiplication distributes over addition in reals)} \\
&= \begin{pmatrix} aa_{11} & \ldots & aa_{1m} \\ \vdots &  \ddots & \vdots \\ aa_{n1} &  \ldots & aa_{nm} \end{pmatrix} + \begin{pmatrix} ab_{11} &  \ldots & ab_{1m} \\  \vdots & \ddots & \vdots \\ ab_{n1} &  \ldots & ab_{nm} \end{pmatrix} \\
&= aA+ aB
\end{align*}
\smallskip

\textbf{8. $(a+b)A = aA+bA$:}
\begin{align*}
(a+b)A &= (a+b)\cdot \begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix}\\
&= \begin{pmatrix} (a+b)a_{11} & \ldots & (a+b)a_{1m} \\ \vdots &  \ddots & \vdots \\ (a+b)a_{n1} &  \ldots & (a+b)a_{nm} \end{pmatrix} \\
&= \begin{pmatrix} aa_{11}+ba_{11} & \ldots & aa_{1m}+ba_{1m} \\ \vdots &  \ddots & \vdots \\ aa_{n1}+ba_{n1} &  \ldots & aa_{nm}+ba_{nm} \end{pmatrix} \text{(since multiplication distributes over addition in reals)} \\
&= \begin{pmatrix} aa_{11} & \ldots & aa_{1m} \\ \vdots &  \ddots & \vdots \\ aa_{n1} &  \ldots & aa_{nm} \end{pmatrix} + \begin{pmatrix} ba_{11} & \ldots & ba_{1m} \\ \vdots &  \ddots & \vdots \\ ba_{n1} &  \ldots & ba_{nm} \end{pmatrix} \\
&= a\begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix} + b\begin{pmatrix} a_{11} & \ldots & a_{1m} \\ \vdots &  \ddots & \vdots \\ a_{n1} &  \ldots & a_{nm} \end{pmatrix}\\
&= aA +bA
\end{align*}
\smallskip

By verifying these 8 properties, we showed that $\mathcal{V}$ in indeed a vector space. 


\end{proof}


\newpage
$\bullet$ \textbf{Problem 2} 
\medskip

\begin{itshape}
Define a new matrix addition for square matrices. $A+B=C$ is defined as follows:

if $A=(a_{ij})$, $B=(b_{ij})$, $C=(c_{ij})$, then $c_{ij}=a_{ij}+b_{ji}$.

For example 
$ \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} + \begin{pmatrix} 5 & 6 \\ 7 & 8 \end{pmatrix} = \begin{pmatrix} 1+5 & 2+7 \\ 3+6 & 4+8 \end{pmatrix}$.

Is the set of $n \times m$ real matrices with this new addition and usual scaler multiplication a vector space?
\end{itshape}
\medskip

\begin{proof} Claim: This is not a vector space
$ $ \newline
We will show that it does not satisfy $(a+b)A = aA+bA$.

Take $a=b=1$ and $A= \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}$. Then
\begin{align*}
(a+b)A &= (1+1)\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix}\\
&= 2 \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} \\
&=\begin{pmatrix} 2\cdot 1 & 2\cdot 2 \\2\cdot  3 & 2\cdot 4 \end{pmatrix}\\
&= \begin{pmatrix} 2 & 4 \\ 6 & 8 \end{pmatrix}
\end{align*}

However,
\begin{align*}
aA+bA &= 1\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} + 1\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} \\
&= \begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} +\begin{pmatrix} 1 & 2 \\ 3 & 4 \end{pmatrix} \\
&= \begin{pmatrix} 1+1 & 2+3 \\ 3+2 & 4+4 \end{pmatrix} \\
&= \begin{pmatrix} 2 & 5 \\ 5 & 8 \end{pmatrix}
\end{align*}
Hence $(a+b)A \ne aA+bA$, and so with this new addition rule, $\mathcal{V}$ is no longer a vector space.

\end{proof}


\newpage
$\bullet$ \textbf{Problem 3}
\medskip

\begin{itshape}
In this problem $\mathcal{V}$ is a vector space over $\mathcal{F}$. $\vec{v}. \vec{w} \in \mathcal{V}$, $\lambda \in \mathcal{F}$. Prove that

i) $\lambda \vec{v} = \lambda \vec{w} \Rightarrow \vec{v} = \vec{w}$ whenever $\lambda \neq 0$

ii) $\alpha \vec{v} = \beta \vec{v} \Rightarrow \alpha = \beta$ whenever $\vec{v} \neq 0$

iii) $\lambda \cdot \vec{v} = \vec{0} \Leftrightarrow \lambda=0$ or $\vec{v} =0 $
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
i) Since $\lambda \ne 0$ is an element of the field $\mathcal{F}$, there exist a multiplicative inverse $\lambda^{-1}$ such that $\lambda \cdot \lambda^{-1} =1$. Then given that $\lambda \vec{v} = \lambda \vec{w}$
$$ \vec{v} = 1 \cdot \vec{v} = \lambda^{-1} \cdot \lambda \cdot \vec{v} = \lambda^{-1} \cdot \lambda \cdot \vec{w} = 1 \cdot \vec{w} = \vec{w}$$
\smallskip

ii) Prove by contradiction. 

Assume that $\vec{v} \ne 0$, $\alpha \vec{v} = \beta \vec{v}$ and $\alpha \ne \beta$. Define $\lambda = \alpha - \beta$ then $\lambda \ne 0$, so there exist an inverse $\lambda^{-1}$. Moreover, $\alpha \vec{v} = \beta \vec{v}$ implies that $(\alpha - \beta) \vec{v} = \lambda \vec{v} =\vec{0}$. Since $a \cdot \vec{0} = \vec{0}$ for all $a \in \mathcal{F}$
\begin{align*}
\vec{0} &= \lambda^{-1} \cdot \vec{0} \\
&= \lambda^{-1} \cdot (\lambda \vec{v})\\
&= 1 \cdot \vec{v}\\
&= \vec{v}
\end{align*}
contradicts that $\vec{v} \ne \vec{0}$. Hence $\alpha = \beta$.
\smallskip

iii) Want to show that $\lambda \cdot \vec{v} = \vec{0}$ implies $\lambda = 0$ or $\vec{v} = \vec{0}$. Prove by 
contradiction, that is, $\lambda \cdot \vec{v} = \vec{0}$, $\lambda \ne 0$ and $\vec{v} \ne \vec{0}$.

Since $\lambda \ne 0$ there exists an inverse $\lambda^{-1}$ such that $\lambda \cdot \lambda^{-1} = 1$. And by the theorem proved in class
\begin{align*}
\vec{0} &= \lambda^{-1} \cdot \vec{0}\\
&= \lambda^{-1} \cdot (\lambda \cdot \vec{v})\\
&= 1 \cdot \vec{v}\\
&= \vec{v}
\end{align*}
contradicts that $\vec{v} \ne \vec{0}$. Hence  $\lambda \cdot \vec{v} = \vec{0} \Rightarrow \lambda = 0$ or $\vec{v} = \vec{0}$.

The converse is trivial by the theorem proved in class that $\lambda \cdot \vec{0} = \vec{0}$ for all $\lambda \in \mathcal{F}$ and $0 \cdot \vec{v} = \vec{0}$ for all $\vec{v} \in \mathcal{V}$. 

\end{proof}


\newpage
$\bullet$ \textbf{Problem 4}
\medskip

\begin{itshape}
Let $\mathcal{S}$ be the set of all real valued differentiable functions $f:(0,1) \to \mathbb{R}$. Prove that $\mathcal{S}$ is a subspace of $\mathbb{R}^{(0,1)}$
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
\textbf{1) $\vec{0} \in \mathcal{S}$:}

The zero vector of the vector space $\mathbb{R}^{(0,1)}$ is the constant zero function, which is clearly differentiable. Hence, $\vec{0} \in \mathcal{S}$.
\smallskip

\textbf{2) closed under addition:}

Let $f, g \in \mathcal{S}$, so $f$ and $g$ are differentiable. From calculus we know the sum of two differentiable functions is differentiable, and clearly the domain of $(f+g)(x)$ is still $(0,1)$. Hence, $(f+g)(x): (0,1) \to \mathbb{R} \in \mathcal{S}$. 
\smallskip

\textbf{3) closed under scalar multiplication:}

Let $f \in \mathcal{S}$, then $f$ is differentiable. Again, from calculus, multiplying a differentiable function by a constant will not change the differentiability of the function, and the domain does not change under this process too. So, $\lambda f: (0,1) \to \mathbb{R} \in \mathcal{S}$.
\smallskip

This shows that $\mathcal{S} \le \mathbb{R}^{(0,1)}$. 
\end{proof}


\newpage
$\bullet$ \textbf{Problem 5}
\medskip

\begin{itshape}
Given an example of a subset $\mathcal{S}$ of $\mathbb{R}^2$ that contains $(0,0)$, is closed under vector addition but it is not a subspace of $\mathbb{R}^2$.
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
Let $\mathcal{S} = \{ (x,y) | x \ge 0, y=0 \}$ (the positive $x$ axis). Then $(0,0) \in \mathcal{S}$. If $\vec{u}, \vec{v} \in \mathcal{S}$, then $\vec{u} = (x_{u},0)$ and $\vec{v} = (x_{v},0)$ with $x_{u}, x_{v} \ge 0$. 

$\vec{u} + \vec{v} = (x_{u}, 0) + (x_{v}, 0) = (x_{u} + x_{v} ,0)$ where $x_{u} + x_{v} \ge 0$. Hence $\vec{u} + \vec{v} \in \mathcal{S}$. That is, $\mathcal{S}$ is closed under vector addition.

However, $\mathcal{S}$ is not a subspace because if taking $\lambda = -1$ and $(1, 0) \in \mathcal{S}$, then $\lambda \cdot (1,0) = -1 \cdot (1,0) = (-1,0) \notin \mathcal{S}$. Thats is, $\mathcal{S}$ is not closed under scalar multiplication, hence not a subspace of $\mathbb{R}^2$.
\end{proof}


\newpage
$\bullet$ \textbf{Problem 6}
\medskip

\begin{itshape}
Assume $\mathcal{V}$ is a vector space and $S_{x}$, $x \in \mathcal{F}$ is a family of subspaces of $\mathcal{V}$. Prove that $\bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$ is a subspace of $\mathcal{V}$.
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
\textbf{1) $\vec{0} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$:}

Since $\mathcal{S}_{x}$ is a subspace of $\mathcal{V}$, $\vec{0} \in \mathcal{S}_{x}$ for all $x \in \mathcal{F}$. Hence it follows that $\vec{0} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$.
\smallskip

\textbf{2) closed under addition:}

Let $\vec{u}, \vec{v} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$, then $\vec{u}, \vec{v} \in \mathcal{S}_{x}$ for all $x \in \mathcal{F}$. Since $\mathcal{S}_{x}$ is a subspace, $\vec{u} + \vec{v} \in \mathcal{S}_{x}$ for all $x \in \mathcal{F}$. This implies that $\vec{u} + \vec{v} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$.
\smallskip

\textbf{3) closed under scalar multiplication:}

Let $\vec{u} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$ and $\lambda$ be a element of the field, then $\vec{u} \in \mathcal{S}_{x}$ for all $x \in \mathcal{F}$. Since $\mathcal{S}_{x}$ is a subspace, $\lambda \vec{u} \in \mathcal{S}_{x}$ for all $x \in \mathcal{F}$. It follows that $\lambda \vec{u} \in \bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$.

Hence, $\bigcap \limits_{x \in \mathcal{F}} \mathcal{S}_{x}$ is a subspace of $\mathcal{V}$.
\end{proof}


\newpage
$\bullet$ \textbf{Problem 7}
\medskip

\begin{itshape}
Assume $\mathcal{V}$ is a vector space and $\mathcal{U}_{1}$, $\mathcal{U}_{2}$, $\mathcal{W}$ are subspaces of $\mathcal{V}$, such that $\mathcal{U}_{1} \oplus \mathcal{W} = \mathcal{U}_{2} \oplus \mathcal{W}$. Does it necessarily follow that $\mathcal{U}_{1}=\mathcal{U}_{2}$? Justify
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
False. Let $\mathcal{V} = \mathbb{R}^2$ and $\mathcal{W} = \mathbb{R}^2, \mathcal{U}_1 = \{ (x, 0 ) | x \in \mathbb{R} \}, \mathcal{U}_2 = \{ (0,0) \}$. Note that $\mathcal{W}$, $\mathcal{U}_1$, and $\mathcal{U}_2$ are indeed subspaces of $\mathcal{V}$. Also notice that $\mathcal{U}_1 \oplus \mathcal{W} = \{ (x,0) | x \in \mathbb{R} \} \oplus \mathbb{R}^2 = \mathbb{R}^2$ and $\mathcal{U}_2 \oplus \mathcal{W} = \{ (0,0) \} \oplus \mathbb{R}^2 = \mathbb{R}^2$.

Hence $\mathcal{U}_{1} \oplus \mathcal{W} = \mathcal{U}_{2} \oplus \mathcal{W}$ but $\mathcal{U}_1 \ne \mathcal{U}_2$, so the statement is false.
\end{proof}


\newpage
$\bullet$ \textbf{Problem 8}
\medskip

\begin{itshape}
Let $\mathcal{U}_{1} = \{ (x,y,0,0) | x, y \in \mathbb{R} \}$ and $\mathcal{U}_{2} = \{ (x,0,z,t) | x, z, t \in \mathbb{R} \}$. $\mathcal{U}_{1}$ and $\mathcal{U}_{2}$ are subspaces of $\mathbb{R}^4$ (you do not need to prove this).

Prove that $\mathcal{U}_{1} + \mathcal{U}_{2}$ is not a direct sum.

Find $\mathcal{U}_{3} \le \mathbb{R}^4$ such that $\mathcal{U}_{1} \oplus \mathcal{U}_{3} = \mathcal{U}_{1} + \mathcal{U}_{2}$.
\end{itshape}
\medskip

\begin{proof}
$ $ \newline
To show $\mathcal{U}_1 + \mathcal{U}_2$ is not a direct sum, we will show that $\mathcal{U}_2 \cap \mathcal{U}_2 \ne \{ \vec{0} \} $, where, in $\mathbb{R}^4$ case, $\vec{0} = (0,0,0,0)$.

Consider the vector $\vec{v} = (1,0,0,0) \in \mathbb{R}^4$. Then $\vec{v}$ is in both $\mathcal{U}_1$ and $\mathcal{U}_{2}$, that is, $(1,0,0,0) \in \mathcal{U}_1 \cap \mathcal{U}_2$. Hence, $\mathcal{U}_2 \cap \mathcal{U}_2 \ne \{ \vec{0} \} $ and $\mathcal{U}_1 + \mathcal{U}_2$ is not a direct sum.

\medskip
Now find $\mathcal{U}_{3} \le \mathbb{R}^4$ such that $\mathcal{U}_{1} \oplus \mathcal{U}_{3} = \mathcal{U}_{1} + \mathcal{U}_{2}$. 

First notice that $\mathcal{U}_1 + \mathcal{U}_2 = \mathbb{R}^4$ since for all $\vec{v} = (x, y, z, t) \in \mathbb{R}^4$, we can write it as $(x, y, z,t) = (x, y, 0, 0) + (0, 0, z, t)$, where trivially $(x, y, 0, 0) \in \mathcal{U}_1$ and $(0, 0, z, t) \in \mathcal{U}_2$.

Take $\mathcal{U}_3 = \{ (0,0,z,t) | z, t \in \mathbb{R} \}$. $\mathcal{U}_3$ is a subspace of $\mathbb{R}^4$ since:

1) $(0,0,0,0) \in \mathcal{U}_3$ (by taking $z, t =0$)

2) closed under addition since for all vector in $\mathcal{U}_3$, their sum will always have first two components to be zero (since $0+0 =0 $).

3) closed under scaler multiplication for similar reasoning as addition (since $\lambda \cdot 0 = 0$).

Clearly that $\mathcal{U}_1 + \mathcal{U}_3 = \mathbb{R}^4$, and to show this is direct sum, we will show that their intersection is the zero vector.

Let $\vec{v} = (x, y, z,t) \in \mathcal{U}_1 \cap \mathcal{U}_3$, then $\vec{v} \in \mathcal{U}_1$ and $\vec{v} \in \mathcal{U}_3$. $\vec{v} \in \mathcal{U}_1$ implies that $z, t = 0$ and $\vec{v} \in \mathcal{U}_3$ implies that $x, y = 0$. Hence $\vec{v} = (0,0,0,0) = \vec{0} $ and so $\mathcal{U}_1 + \mathcal{U}_3$ is a direct sum and $\mathcal{U}_1 \oplus \mathcal{U}_3 = \mathcal{U}_1 + \mathcal{U}_2$.

\end{proof}


\newpage
$\bullet$ \textbf{Problem 9}
\medskip

\begin{itshape}
Let $\mathcal{S}$ be the set of all complex valued sequences $\{ x_{n} \}$ with the property that there is $k \in \mathbb{N}$ such that for all $n \ge k$, $x_{n} = 0$. Prove $\mathcal{S}$ is a subspace of $\mathbb{C}^\infty$.
\end{itshape}
\medskip

\begin{proof}
$ $ \newline

\textbf{1) $\vec{0} \in \mathcal{S}$:}

$\vec{0}$ in $\mathbb{C}^\infty$ is the constant zero sequence. Clearly it converges to $0$, so $\vec{0} \in \mathcal{S}$.

\textbf{2) closed under addition:}

Let $\{ x_n \}, \{ y_n \} \in \mathcal{S}$, then there exists $k_x \in \mathbb{N}$ such that for all $n \ge k_x$, $x_n =0$, similarly there exist $k_y$ for $\{ y_n \}$. Take $k = min\{ k_x, k_y \}$. Then for all $n \ge k$, $x_n = y_n =0$. So for all $n \ge k$, $ x_n + y_n \in \{x_n\} + \{y_n \}$ is zero and hence $\{x_n\} + \{y_n \} \in \mathcal{S}$.

\textbf{(3) closed under scalar multiplication:}

Let $\{ x_n \} \in \mathcal{S}$, $ \lambda \in \mathcal{F} = \mathbb{C}$, then there exists $k \in \mathbb{N}$ such that for all $n \ge k$, $x_n =0$. With the same $k$, $\lambda x_n = 0$ for all $n \ge k$ since $\lambda \cdot 0$ is always zero. Hence the sequence $\lambda \{x_n \}$ converges to zero and so it's in $\mathcal{S}$.
\end{proof}

\end{document}